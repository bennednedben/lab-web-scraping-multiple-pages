{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d06aa9",
   "metadata": {},
   "source": [
    "Instructions Part 2\n",
    "\n",
    "Practice web scraping. This is not involved with the GNOD project of the week\n",
    "As you've seen, scraping the internet is a skill that can get you all sorts of information. Here are some little challenges that you can try to gain more experience in the field. Open a new Jupyter notebook and scrape at least 3 of these sites.\n",
    "\n",
    "Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'\n",
    "\n",
    "Find the number of titles that have changed in the United States Code since its last release point: url = 'http://uscode.house.gov/download/download.shtml'\n",
    "\n",
    "Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten'\n",
    "\n",
    "Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "\n",
    "List all language names and number of related articles in the order they appear in wikipedia.org: url = 'https://www.wikipedia.org/'\n",
    "\n",
    "A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'\n",
    "\n",
    "Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678ef68",
   "metadata": {},
   "source": [
    "# Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4058a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d185c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. url: we start with the 'second' page. Show that you can start whenever you want\n",
    "url = 'https://en.wikipedia.org/wiki/Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2094a8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. download html with a get request\n",
    "response = requests.get(url)\n",
    "response.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972fb72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ff85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python =soup.select(\"#mw-content-text > div.mw-parser-output a\")\n",
    "# pytab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b38fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wiktionary.org/wiki/Python\n",
      "https://en.wiktionary.org/wiki/python\n",
      "/w/index.php?title=Python&action=edit&section=1\n",
      "/wiki/Pythonidae\n",
      "/wiki/Python_(genus)\n",
      "/wiki/Python_(mythology)\n",
      "/w/index.php?title=Python&action=edit&section=2\n",
      "/wiki/Python_(programming_language)\n",
      "/wiki/CMU_Common_Lisp\n",
      "/wiki/PERQ#PERQ_3\n",
      "/w/index.php?title=Python&action=edit&section=3\n",
      "/wiki/Python_of_Aenus\n",
      "/wiki/Python_(painter)\n",
      "/wiki/Python_of_Byzantium\n",
      "/wiki/Python_of_Catana\n",
      "/wiki/Python_Anghelo\n",
      "/w/index.php?title=Python&action=edit&section=4\n",
      "/wiki/Python_(Efteling)\n",
      "/wiki/Python_(Busch_Gardens_Tampa_Bay)\n",
      "/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)\n",
      "/w/index.php?title=Python&action=edit&section=5\n",
      "/wiki/Python_(automobile_maker)\n",
      "/wiki/Python_(Ford_prototype)\n",
      "/w/index.php?title=Python&action=edit&section=6\n",
      "/wiki/Python_(missile)\n",
      "/wiki/Python_(nuclear_primary)\n",
      "/wiki/Colt_Python\n",
      "/w/index.php?title=Python&action=edit&section=7\n",
      "/wiki/Python_(codename)\n",
      "/wiki/Python_(film)\n",
      "/wiki/Monty_Python\n",
      "/wiki/Python_(Monty)_Pictures\n",
      "/wiki/Timon_of_Phlius\n",
      "/w/index.php?title=Python&action=edit&section=8\n",
      "/wiki/Pyton\n",
      "/wiki/Pithon\n",
      "/wiki/File:Disambig_gray.svg\n",
      "/wiki/Help:Disambiguation\n",
      "https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0\n"
     ]
    }
   ],
   "source": [
    "python_list = []\n",
    "for p in python:\n",
    "    link = p.get(\"href\")\n",
    "    print(link)\n",
    "    if link is not None:\n",
    "        if ((\"/wiki\" in link)): \n",
    "            python_list.append(p[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0a35c",
   "metadata": {},
   "source": [
    "# Create a Python list with the top ten FBI's Most Wanted names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2839738",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b8837a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. download html with a get request\n",
    "response2 = requests.get(url_2)\n",
    "response2.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e55dabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. parse html (create the 'soup')\n",
    "soup2 = BeautifulSoup(response2.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd04168b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OMAR ALEXANDER CARDENAS'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select(\" h3 > a\")[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f182cad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OMAR ALEXANDER CARDENAS', 'ALEXIS FLORES', 'BHADRESHKUMAR CHETANBHAI PATEL', 'ALEJANDRO ROSALES CASTILLO', 'YULAN ADONAY ARCHAGA CARIAS', 'RUJA IGNATOVA', 'ARNOLDO JIMENEZ', 'MICHAEL JAMES PRATT', 'JOSE RODOLFO VILLARREAL-HERNANDEZ', 'RAFAEL CARO-QUINTERO']\n"
     ]
    }
   ],
   "source": [
    "#initialize empty lists\n",
    "top_ten = []\n",
    "\n",
    "# define the number of iterations of our for loop\n",
    "num_iter = len(soup2.select(\" h3 > a\"))\n",
    "\n",
    "MW = soup2.select(\" h3 > a\")\n",
    "# iterate through the result set and retrive all the data\n",
    "for i in range(num_iter):\n",
    "    top_ten.append(MW[i].get_text())\n",
    "\n",
    "print(top_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26668e64",
   "metadata": {},
   "source": [
    "# Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "213ea96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = 'https://www.data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5134c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = requests.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ac05938",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response3.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58582f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Business+and+economy\">Business and economy</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Crime+and+justice\">Crime and justice</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Defence\">Defence</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Education\">Education</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Environment\">Environment</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Government\">Government</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Government+spending\">Government spending</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Health\">Health</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Mapping\">Mapping</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Society\">Society</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Towns+and+cities\">Towns and cities</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Transport\">Transport</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Digital+service+performance\">Digital service performance</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Government+reference+data\">Government reference data</a>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\" h3 > a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4192d5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize empty lists\n",
    "earthquakes_list = []\n",
    "\n",
    "# define the number of iterations of our for loop\n",
    "num_iter = len(soup.select(\" h3 > a\"))\n",
    "\n",
    "earthquakes = soup.select(\" h3 > a\")\n",
    "# iterate through the result set and retrive all the data\n",
    "for i in range(num_iter):\n",
    "    earthquakes_list.append(earthquakes[i].get_text())\n",
    "\n",
    "earthquakes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32349d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
